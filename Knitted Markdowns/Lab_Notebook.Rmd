---
title: "Lab Notebook"
output: html_document
date: "2024-01-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(BradleyTerry2)
library(TennisBT)
library(ggthemes)
library(cowplot)
```

# Code for Section 2: Data

Here we will be performing some basic analysis on the data to get an idea of any major problems with the dataset before we build the model. I.e. if we find any irrelevant data that we can remove this will greatly simplify things later down the line.

Firstly we create our set of years and define the test set to be the year 2023

```{r}
#List of years from 1968 to 2023
years<-seq(1968,2023)

#Test set year
test_year<-2023

#Loading test set
library(readr)
test_set<-read_csv(paste("tennis_wta/wta_matches_",as.character(test_year),".csv", sep=""),show_col_types = FALSE)
```

Next we want to see how much data is actually available. From briefly skimming through the datasets we saw that not all years contain the same amount of variables. Therefore we quantify the amount of variables by measuring how many columns in the data frame actually contain data. Then we will also potentially use age and height as covariates in our model, although again by quickly looking at the .csv files we can see a fair amount of missing data. Hence we also measure this and see if it changes by year.

```{r}
#Checking if a column is empty
containsdata<-function(column){
  if (all(is.na(column))){
    return(FALSE)
  }
  else{
    return(TRUE)
  }
}

#How many columns contain data
fullcolumns<-function(data){
  num<-0
  for (i in 1:dim(data)[2]){
    if (containsdata(data[,i])){
      num<-num+1
    }
  }
  return(num)
}
```

```{r}
#Checking for missing data in age
ismissing_age<-function(data){
  num_missing<-0
  for (column in c('winner_age','loser_age')){
    for (j in 1:dim(data[,column])[1]){
      if (all(is.na(data[j,column]))){
        num_missing<-num_missing+1
      }
    }
  }
  return(num_missing)
}

#Checking for missing data in height
ismissing_height<-function(data){
  num_missing<-0
  for (column in c('winner_ht','loser_ht')){
    for (j in 1:dim(data[,column])[1]){
      if (all(is.na(data[j,column]))){
        num_missing<-num_missing+1
      }
    }
  }
  return(num_missing)
}
```

```{r include=FALSE}
#Finding amount of columns, missing height and age data for each year

M<-length(years)
fullcols<-rep(0,M)
mis_ages<-rep(0,M)
mis_hts<-rep(0,M)
for (i in 1:M){
  data<-read_csv(paste("tennis_wta/wta_matches_",as.character(years[i]),".csv", sep=""),show_col_types = FALSE)
  fullcols[i]<-fullcolumns(data)
  mis_ages[i]<-ismissing_age(data)/(2*dim(data)[1])
  mis_hts[i]<-ismissing_height(data)/(2*dim(data)[1])
}
```

By plotting the amount of variables (non-zero columns) and percentage of missing data across time, we can see that the older data is much worse than the current, which is to be expected. For instance, the data around 1970 only has about half the variables recorded as in 2023, and over half the heights of players are not recorded. We can also see that for modern data, the proportion of missing age data is negligible. As expected also the amount of height data collected increases with time, although strangely falters past the 2010s. However we will see later why this might be.

```{r}
#Plotting results 
library(ggplot2)
library(ggthemes)
library(cowplot)

#Creating data frame of results
Missing_Data<-data_frame(Year=years,Mis_Age =mis_ages,Mis_hts=mis_hts,Fullcols=fullcols)

#Plotting
plot1<-ggplot(Missing_Data,aes(x=Year,y=Fullcols))+
  geom_bar(stat="identity",fill='darkblue') +
  theme_solarized() +
  labs(x='Year',y='Number of Variables',title='Available Data per Year')
plot2<-ggplot(Missing_Data,aes(x=Year,y=Mis_Age))+
  geom_bar(stat="identity",fill='darkred') +
  theme_solarized() +
  labs(x='Year',y='Proportion of Missing Data',title=' Missing Age Data per Year')
plot3<-ggplot(Missing_Data,aes(x=Year,y=Mis_hts))+
  geom_bar(stat="identity",fill='darkgreen') +
  theme_solarized() +
  labs(x='Year',y='Proportion of Missing Data',title=' Missing Height Data per Year')

plot_grid(plot1,plot2,plot3,nrow=1)
```

Now we have justification for sticking mostly to modern data, we can start to think about which players are relevant in our model. We suspect that not all players need to necessarily be included. For instance, a rogue player that has only played one game will input very little into our model's predictive power. We can quantify this suspicion by plotting each players total number of games played from 2020-2022.

```{r include=FALSE}
library(dplyr)
library(tidyr)

#Creating array of all distinct competitors from 2020-2022
num_names<-c()
for (i in 53:(M-1)){
  data<-read_csv(paste("tennis_wta/wta_matches_",as.character(years[i]),".csv", sep=""),show_col_types = FALSE)
  num_names<-append(num_names,c(as.matrix(data[,'winner_name']),as.matrix(data[,'loser_name'])))
}
names<-unique(num_names)
```

By plotting a histogram of frequencies (Left), it is immediately obvious that our worries were correct, and a large proportion of players have played an insignificant amount of games over three years. In fact by zooming in on this histogram (right), a lot of players have indeed only played one game and then never played again.

```{r warning=FALSE}
#Finding how many games each player has played from 2020-2022
N<-length(names)
num_games<-rep(0,N)
for (i in 1:N){
  num_games[i]<-length(which(num_names==names[i]))
}

#Creating data frame of results
Num_Game_Data<-data_frame(Num_Games=num_games)

#Plotting
plot4<-ggplot(Num_Game_Data,aes(x=Num_Games))+
  theme_solarized() +
  geom_histogram(binwidth = 1,fill='darkblue') +
  labs(x='Games Played',y='Frequency',title='Number of Games played per Player (2020-2022)')

plot5<-ggplot(Num_Game_Data,aes(x=Num_Games))+
  theme_solarized() +
  geom_histogram(binwidth = 1,fill='darkblue',col='white') +
  xlim(c(0,10)) +
  labs(x='Games Played',y='Frequency',title='Number of Games played per Player (2020-2022) [Zoomed]')

plot_grid(plot4,plot5,nrow=1)
```

# Code for Section 3: Model and Evaluation Techniques

# Code for Section 4: Results

<<<<<<< Updated upstream
Before fitting the model on our training set, we must install the package that contains our training and test datasets:

```{r}
install.packages()
library()
data()
data()
```

For model selection, we used a stepwise approach. The code used to produce the results in Table 2 is given below, along with the standard Bradley-Terry model with no covariates.

```{r}
##### Without covariates
data_for_model0 <- list(matches=matches, predictors=predictors)
data_for_model_test0 <- list(matches=matches_test, predictors=predictors[players_test,] )
model0 <- BTm(rep(1,dim(matches)[1]), player1=Winner, player2=Loser, data=data_for_model0)

##### With covariates
model_full <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Hand[Player] + Height[Player] + Surface + Ace + Df + Svpt +
                FirstIn + FirstWon + SecondWon + SvGms + BpSaved + BpFaced + (1|Player),
              id="Player", data=data_for_model)
# Removing SvGms
model1 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
                    formula = ~  Hand[Player] + Height[Player] + Surface + Ace + Df + Svpt +
                      FirstIn + FirstWon + SecondWon + BpSaved + BpFaced + (1|Player),
                    id="Player", data=data_for_model)
# Removing BpFaced
model2 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Hand[Player] + Height[Player] + Surface + Ace + Df + Svpt +
                FirstIn + FirstWon + SecondWon + BpSaved + (1|Player),
              id="Player", data=data_for_model)
# Removing FirstIn
model3 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Hand[Player] + Height[Player] + Surface + Ace + Df + Svpt +
                FirstWon + SecondWon + BpSaved + (1|Player),
              id="Player", data=data_for_model)
# Removing BpSaved
model4 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Hand[Player] + Height[Player] + Surface + Ace + Df + Svpt +
                FirstWon + SecondWon + (1|Player),
              id="Player", data=data_for_model)
# Removing Hand (although all variables are already signif at <0.1)
model5 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Height[Player] + Surface + Ace + Df + Svpt +
                FirstWon + SecondWon + (1|Player),
              id="Player", data=data_for_model)
# Removing SecondWon
model6 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Height[Player] + Surface + Ace + Df + Svpt +
                FirstWon + (1|Player),
              id="Player", data=data_for_model)
# Removing Height
model7 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Surface + Ace + Df + Svpt +
                FirstWon + (1|Player),
              id="Player", data=data_for_model)
# Removing Df
model8 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Surface + Ace + Svpt +
                FirstWon + (1|Player),
              id="Player", data=data_for_model)
# Removing Ace
model9 <- BTm(rep(1,dim(matches)[1]), player1=winners, player2=losers,
              formula = ~  Surface + Svpt +
                FirstWon + (1|Player),
              id="Player", data=data_for_model)


summary(model0)
summary(model_full)
summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
summary(model6)
summary(model7)
summary(model8)
summary(model9)
summary(model10)

pred0 <- predict(model0, newdata=data_for_model_test0, type="response", se.fit=TRUE)
pred_full <- predict(model_full, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred1 <- predict(model1, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred2 <- predict(model2, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred3 <- predict(model3, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred4 <- predict(model4, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred5 <- predict(model5, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred6 <- predict(model6, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred7 <- predict(model7, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred8 <- predict(model8, newdata=data_for_model_test, type="response", se.fit=TRUE)
pred9 <- predict(model9, newdata=data_for_model_test, type="response", se.fit=TRUE)

mean(pred0$fit)
length(which(pred0$fit>0.5))
length(which(pred0$fit>0.5)) / length(pred0$fit)

mean(pred_full$fit)
length(which(pred_full$fit>0.5))
length(which(pred_full$fit>0.5)) / length(pred_full$fit)

mean(pred1$fit)
length(which(pred1$fit>0.5))
length(which(pred1$fit>0.5)) / length(pred1$fit)

mean(pred2$fit)
length(which(pred2$fit>0.5))
length(which(pred2$fit>0.5)) / length(pred2$fit)

mean(pred3$fit)
length(which(pred3$fit>0.5))
length(which(pred3$fit>0.5)) / length(pred3$fit)

mean(pred4$fit)
length(which(pred4$fit>0.5))
length(which(pred4$fit>0.5)) / length(pred4$fit)

mean(pred5$fit)
length(which(pred5$fit>0.5))
length(which(pred5$fit>0.5)) / length(pred5$fit)

mean(pred6$fit) 
length(which(pred6$fit>0.5))
length(which(pred6$fit>0.5)) / length(pred6$fit)

mean(pred7$fit) 
length(which(pred7$fit>0.5))
length(which(pred7$fit>0.5)) / length(pred7$fit)

mean(pred8$fit)
length(which(pred8$fit>0.5))
length(which(pred8$fit>0.5)) / length(pred8$fit)

mean(pred9$fit)
length(which(pred9$fit>0.5))
length(which(pred9$fit>0.5)) / length(pred9$fit)
```


Now we will plot the change in predicted rankings over time, and see how this correlates with the actual WTA rankings. First we will use a weighting of 0.9 to find the 'best five players' according to our model over the entire training set.




```{r warning=FALSE}
# PICKING 5 MOST IMPORTANT PLAYERS

#Loading data
Big_Data<-TennisTidyr(2013,2022,2023,5)
Big_Train<-Big_Data$train
players<-Big_Data$main_names

#Number of top players
M<-5

#Training model
weights <- get_recency_weights(Big_Train, 0.9)
Big_Model <- BTm(outcome=1, factor(winner_name, levels=players), factor(loser_name, levels=players), 
                    weights = weights, id='player', data=Big_Train)

#Finding top players
Big_Rankings<-data_frame(Players=players,Ranks=BTabilities(Big_Model)[,1])
Big_Rankings<-Big_Rankings[order(Big_Rankings$Ranks,decreasing=TRUE),]
top_players<-Big_Rankings$Players[1:M]

top_players
```

Now we define a function for estimating these players ranks per year, now using a weighting of 0.1 and a timescale of 3 years.

```{r}
#Function for finding rankings
Ranks<-function(year){
  #Loading data
  Data<-TennisTidyr(year-3,year,2023,1)
  Train<-Data$train
  players<-Data$main_names


#Training model
weights <- get_recency_weights(Train, 0.1)
Model <- BTm(outcome=1, factor(winner_name, levels=players), factor(loser_name, levels=players), 
                    weights = weights, id='player', data=Train)

#Finding top players
Rankings<-data_frame(Players=players,Ranks=BTabilities(Model)[,1])
Rankings<-Rankings[order(Rankings$Ranks,decreasing=TRUE),]

#Finding the ranks of each top player. If they have none, we output NA
ranks<-rep(0,M)
for (i in 1:M){
  if(top_players[i] %in% Rankings$Players){
  ranks[i]<-which(Rankings$Players == top_players[i])
  }
  else{
    ranks[i]<-NA
  }
}
return(ranks)
}
```

Using this function, we call it for each year from 2016 to 2022, and store the data in a matrix.

```{r warning=FALSE}
#Matrix for rankings
Rankings_Mat<-matrix(NA,nrow=M,ncol=7)

for (i in 2016:2022){
  Rankings_Mat[,i-2015]<-Ranks(i)
}
```

We then transform this matrix to be formatted correctly for ggplot2, then plot the results.

```{r}
library(scales)
library(ggthemes)
n=7

#Transforming data to fit ggplot2
Rankings_Data<-as.data.frame(t(Rankings_Mat),row.names = seq(2016,2022))
colnames(Rankings_Data)<-top_players
longDat <- Rankings_Data %>% pivot_longer(cols = everything(), names_to = "Players", values_to = "Ranks") %>% dplyr::arrange(Players)
longerDat<-longDat %>% group_by(Players) %>%
            slice(1:n) %>%
            mutate(Year = as.numeric(row_number()+2015))
breaks = seq(min(longerDat$Year),max(longerDat$Year), length.out = n)

#Plotting
timeplot1<-ggplot(longerDat,aes(x = Year, y = Ranks, col = Players)) +
            geom_point() +
            geom_line() +
  theme_solarized() +
  scale_y_reverse() +
   theme(axis.text.x = element_text(angle = 50, vjust = 1, hjust = 1)) +
  scale_x_continuous(labels = label_number(accuracy = 1),breaks=breaks) +
  labs(x='Year',y='Ranking',title='Rankings from 2016-2022')
```

We then repeat this process, except now looking for the WTA ranking instead of our own. We can then plot the WTA ranking over ours.

```{r}
#PLOTTING WTA RANK AGAINST OURS

#Function for finding WTA rankings
WTA_Ranks<-function(year){
  data<-read.csv(paste('data/wta_matches_',year,'.csv',sep=''))
  ranks<-rep(NA,M)
  for (i in 1:M){
    possible_ranks<-data$winner_rank[data$winner_name==top_players[i]]
    if(length(possible_ranks>0)){
      ranks[i]<-min(possible_ranks)
    }
  }
  return(ranks)
}

#Matrix for rankings
WTA_Rankings_Mat<-matrix(NA,nrow=M,ncol=7)
for (i in 2016:2022){
  WTA_Rankings_Mat[,i-2015]<-WTA_Ranks(i)
}

#Transforming Data for ggplot2
WTA_Rankings_Data<-as.data.frame(t(WTA_Rankings_Mat),row.names = seq(2016,2022))
colnames(WTA_Rankings_Data)<-top_players
longDat <- WTA_Rankings_Data %>% pivot_longer(cols = everything(), names_to = "Players", values_to = "Ranks") %>% dplyr::arrange(Players)
WTA_longerDat<-longDat %>% group_by(Players) %>%
            slice(1:7) %>%
            mutate(Year = as.numeric(row_number()+2015))

#Removing anomaly
WTA_longerDat$Ranks[WTA_longerDat$Players=='Iga Swiatek' & WTA_longerDat$Year==2018]<-NA

#Plotting with Elina Svitolina removed
timeplot2<-ggplot(longerDat[!longerDat$Players=='Elina Svitolina',],aes(x = Year, y = Ranks, col = Players)) +
            geom_point() +
            geom_line() +
    geom_line(data=WTA_longerDat[!WTA_longerDat$Players=='Elina Svitolina',],aes(x = Year, y=Ranks, col=Players),linetype=3) +
  theme_solarized() +
  scale_y_reverse() +
   theme(axis.text.x = element_text(angle = 50, vjust = 1, hjust = 1)) +
  scale_x_continuous(labels = label_number(accuracy = 1),breaks=breaks) +
  labs(x='Year',y='Ranking',title='Rankings from 2016-2022') 
```

```{r warning=FALSE}
#FINAL OUTPUT
plot_grid(timeplot1,timeplot2,nrow=1)
```

# Github

https://github.com/oijbaker/Tennis.git

